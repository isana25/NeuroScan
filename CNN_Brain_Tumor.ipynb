{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Brain Tumor Detection using CNN + Gradio\n",
        "\n",
        "This project builds a deep learning model to **detect brain tumors** in MRI scans using a **Convolutional Neural Network (CNN)**. A user-friendly **Gradio interface** allows users to upload an image and get a prediction: **Tumor** or **No Tumor**.\n",
        "\n",
        "## ğŸ“ Dataset Used\n",
        "\n",
        "**[Brain MRI Images for Brain Tumor Detection](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection)** â€“ from Kaggle\n",
        "\n",
        "- Contains MRI scans labeled as:\n",
        "  - âœ… `yes` (tumor present)\n",
        "  - âŒ `no` (no tumor)\n",
        "\n",
        "\n",
        "## ğŸ”§ What the Project Does\n",
        "\n",
        "1. **Fetches dataset directly from Kaggle** using Kaggle API  \n",
        "2. **Preprocesses MRI images**:\n",
        " - Resize to 128x128\n",
        " - Normalize pixel values\n",
        " - Convert labels to categorical\n",
        "3. **Builds a CNN model** using TensorFlow/Keras\n",
        "4. **Trains the model** on the MRI images (80% train, 20% test)\n",
        "5. **Creates a Gradio web interface** where users can upload MRI scans for prediction\n",
        "\n",
        "\n",
        "## ğŸ§  Model Architecture\n",
        "\n",
        "```text\n",
        "Input: 128x128 RGB MRI image\n",
        "\n",
        "Conv2D (32 filters) â†’ MaxPooling  \n",
        "Conv2D (64 filters) â†’ MaxPooling  \n",
        "Flatten â†’ Dropout  \n",
        "Dense (64) â†’ Dense (2 - softmax)\n"
      ],
      "metadata": {
        "id": "LuMj2UEbPTun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¦ 1. Install dependencies\n",
        "!pip install -q kagglehub gradio tensorflow opencv-python-headless matplotlib\n",
        "\n",
        "# ğŸ“¥ 2. Download dataset using kagglehub\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "dataset_path = kagglehub.dataset_download('navoneel/brain-mri-images-for-brain-tumor-detection')\n",
        "print('âœ… Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXHz7u9APqhy",
        "outputId": "90cff75f-e558-4ac2-d4d3-0053d204cd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§¹ 3. Load and preprocess the data\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "categories = [\"yes\", \"no\"]\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in categories:\n",
        "    path = os.path.join(dataset_path, category)\n",
        "    class_num = categories.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "            img_array = cv2.resize(img_array, (128, 128))\n",
        "            data.append(img_array)\n",
        "            labels.append(class_num)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "data = np.array(data) / 255.0\n",
        "labels = to_categorical(labels, 2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "print(\"âœ… Data loaded and preprocessed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbf00zA6QQyN",
        "outputId": "18d0cc5e-be8c-4909-a2a4-caacb5e86171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data loaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ—ï¸ 4. Build and train the CNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "print(\"âœ… Model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV12CalBQV3c",
        "outputId": "80948b01-a36e-416a-bb2e-447763a3e833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 783ms/step - accuracy: 0.6240 - loss: 1.2669 - val_accuracy: 0.8039 - val_loss: 0.5750\n",
            "Epoch 2/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.7890 - loss: 0.5491 - val_accuracy: 0.7255 - val_loss: 0.5525\n",
            "Epoch 3/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 699ms/step - accuracy: 0.7761 - loss: 0.5207 - val_accuracy: 0.7647 - val_loss: 0.5413\n",
            "Epoch 4/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8039 - loss: 0.4382 - val_accuracy: 0.8235 - val_loss: 0.4522\n",
            "Epoch 5/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 774ms/step - accuracy: 0.8246 - loss: 0.4543 - val_accuracy: 0.8039 - val_loss: 0.4793\n",
            "âœ… Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§ª 5. Create Gradio interface for prediction\n",
        "import gradio as gr\n",
        "\n",
        "def predict_tumor(image):\n",
        "    image = cv2.resize(image, (128, 128)) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    prediction = model.predict(image)[0]\n",
        "    return {\n",
        "        \"Tumor\": float(prediction[0]),\n",
        "        \"No Tumor\": float(prediction[1])\n",
        "    }\n",
        "\n",
        "gr.Interface(\n",
        "    fn=predict_tumor,\n",
        "    inputs=gr.Image(type=\"numpy\", label=\"Upload Brain MRI\"),\n",
        "    outputs=gr.Label(num_top_classes=2),\n",
        "    title=\"ğŸ§  Brain Tumor Detector\",\n",
        "    description=\"Upload a brain MRI image to detect whether a brain tumor is present.\",\n",
        "    theme=\"default\"\n",
        ").launch(share=True, debug=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XrqO7icYTMdZ",
        "outputId": "3997e6c7-f980-49c6-848e-ac3bcc2641bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5c529356fb09e8cf19.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5c529356fb09e8cf19.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2191, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1702, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4-3432847633.py\", line 5, in predict_tumor\n",
            "    image = cv2.resize(image, (128, 128)) / 255.0\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "cv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
          ]
        }
      ]
    }
  ]
}